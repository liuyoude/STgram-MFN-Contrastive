version: STgram-MFN-Contrastive-pretrain-NTXent
# NTXent is the pretrain loss, modified as supervised contrastive loss, input need same samples from all different classes
# dir / file
model_dir: ./model_params
result_dir: ./results
result_file: result.csv
data_dir: ../../data/dataset
pre_data_dir: ../../data/pre_data
process_machines:
  - pump
  - slider
  - fan
  - valve
  - ToyCar
  - ToyConveyor

# p_AUC
max_fpr: 0.1

# preprocess
sr: 16000
n_mels: 128 # 128
frames: 313
skip_frames: 1
n_fft: 1024
hop_length: 512
win_length: 1024
power: 2.0

num_classes: 41
pretrain: True
contrain: False
# pretrain
pretrain_loss: "ntxent" # ntxent, supcon
con_epochs: 101
con_batch_size: 6
con_lr: 5e-4
t: 0.1
con_file: 313frames_train_path_list_ID_dict.db
device_ids:
#  - 0
#  - 1
#  - 3
#  - 2
#  - 6
#  - 7
  - 4
  - 5

# fine-tune
seed: 526
epochs: 300
batch_size: 128
workers: 16
lr: 1e-4
wd: 1e-6
cuda: True
log_every_n_steps: 20
use_arcface: True
m: 1.0
s: 30
sub_center: 1
ft_ids:
#  - 0
#  - 1
#  - 3
#  - 2
  - 4
  - 5
#  - 6
#  - 7

# loss
lamda: 0.01
# margin to positive samples in contrastive learning
ntxent_margin: False
supcon_margin: False

# map machine ID to label
ID_factor: {
       fan: 0,
       pump: 1,
       slider: 2,
       valve: 3,
       ToyCar: 4,
       ToyConveyor: 5,
}
